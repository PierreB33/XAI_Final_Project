"""
Utilitaires XAI supplÃ©mentaires
"""

import numpy as np
import matplotlib.pyplot as plt
from typing import Dict, List, Tuple


class GradCAMVisualizer:
    """Classe pour visualiser et analyser les rÃ©sultats Grad-CAM"""
    
    @staticmethod
    def create_overlay(original_image, heatmap, alpha=0.5):
        """
        CrÃ©er une superposition entre l'image originale et la heatmap
        
        Args:
            original_image: Image originale
            heatmap: Heatmap gÃ©nÃ©rÃ©e
            alpha: Transparence de la heatmap
            
        Returns:
            Image superposÃ©e
        """
        # Normaliser la heatmap entre 0 et 1
        heatmap_normalized = (heatmap - np.min(heatmap)) / (np.max(heatmap) - np.min(heatmap) + 1e-8)
        
        # CrÃ©er l'image avec couleur jet
        heatmap_colored = plt.cm.jet(heatmap_normalized)
        
        # Superposer
        overlay = alpha * heatmap_colored[:, :, :3] + (1 - alpha) * (original_image / 255.0)
        
        return (overlay * 255).astype(np.uint8)


class ExplanationAnalyzer:
    """Analyser et comparer les explications"""
    
    @staticmethod
    def compare_xai_results(results_dict: Dict) -> Dict:
        """
        Analyser et comparer les rÃ©sultats de plusieurs mÃ©thodes XAI
        
        Args:
            results_dict: Dictionnaire avec les rÃ©sultats de chaque mÃ©thode
            
        Returns:
            Analyse comparative
        """
        analysis = {
            'methods_used': [],
            'methods_failed': [],
            'consistency_score': 0.0
        }
        
        for method, result in results_dict.items():
            if 'error' not in result:
                analysis['methods_used'].append(method)
            else:
                analysis['methods_failed'].append(method)
        
        return analysis
    
    @staticmethod
    def calculate_explanation_quality(explanation_dict: Dict) -> float:
        """
        Calculer une mÃ©trique de qualitÃ© pour une explication
        
        Args:
            explanation_dict: RÃ©sultat d'une explication
            
        Returns:
            Score de qualitÃ© (0-1)
        """
        # Cette mÃ©trique pourrait Ãªtre basÃ©e sur plusieurs critÃ¨res
        # Pour l'instant, retourner 0.5 comme placeholder
        return 0.5


class InteractiveExplainer:
    """Classe pour les explications interactives"""
    
    @staticmethod
    def create_detailed_report(prediction_result: Dict, xai_results: Dict) -> str:
        """
        CrÃ©er un rapport dÃ©taillÃ© combinant prÃ©diction et XAI
        
        Args:
            prediction_result: RÃ©sultat de la prÃ©diction
            xai_results: RÃ©sultats des explications XAI
            
        Returns:
            Rapport texte dÃ©taillÃ©
        """
        report = f"""
â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘          RAPPORT D'ANALYSE DEEPFAKE AUDIO DÃ‰TAILLÃ‰           â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

ğŸ“Š RÃ‰SULTAT DE LA PRÃ‰DICTION:
  â€¢ Label: {prediction_result.get('predicted_label', 'N/A')}
  â€¢ Confiance: {prediction_result.get('confidence', 0):.2%}
  â€¢ ProbabilitÃ© RÃ‰EL: {prediction_result.get('real_probability', 0):.4f}
  â€¢ ProbabilitÃ© FAUX: {prediction_result.get('fake_probability', 0):.4f}
  â€¢ ModÃ¨le: {prediction_result.get('model_type', 'N/A')}

ğŸ” EXPLICATIONS XAI:
"""
        
        if xai_results:
            for method, result in xai_results.items():
                if 'error' not in result:
                    report += f"  âœ“ {method.upper()}: SuccÃ¨s\n"
                else:
                    report += f"  âœ— {method.upper()}: Ã‰chouÃ© - {result['error']}\n"
        
        report += "\nâ•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—\n"
        
        return report
