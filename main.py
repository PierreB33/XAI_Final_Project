#!/usr/bin/env python3
"""
Pipeline complet de d√©tection deepfake audio avec XAI
Utilisation: python main.py <audio_file> [--model mobilenet] [--output ./results]
"""

import sys
import os
import json
import argparse
from pathlib import Path
import matplotlib.pyplot as plt
import matplotlib
matplotlib.use('Agg')  # Mode non-interactif

# Configuration du chemin
sys.path.insert(0, str(Path(__file__).parent))

from backend.deepfake_detector import DeepfakeAudioDetector
from backend.xai_explainer import XAIExplainer
from backend.validators import AudioValidator, SafeDeepfakeDetector
from backend.utils import ExplanationVisualizer, PredictionReport
from backend.spectrogram_converter import get_audio_info


def create_output_dir(output_dir):
    """Cr√©er le r√©pertoire de sortie"""
    os.makedirs(output_dir, exist_ok=True)
    return output_dir


def save_results(results, output_dir, audio_filename):
    """Sauvegarder tous les r√©sultats"""
    base_name = Path(audio_filename).stem
    
    # Sauvegarder JSON de pr√©diction
    pred_file = os.path.join(output_dir, f"{base_name}_prediction.json")
    with open(pred_file, 'w') as f:
        json.dump(results['prediction'], f, indent=2)
    
    # Sauvegarder Grad-CAM
    if 'grad_cam' in results['xai'] and results['xai']['grad_cam']:
        grad_cam_file = os.path.join(output_dir, f"{base_name}_grad_cam.png")
        plt.figure(figsize=(12, 4))
        plt.imshow(results['xai']['grad_cam']['superposed_image'])
        plt.title(f"Grad-CAM - {results['prediction']['predicted_label']} ({results['prediction']['confidence']:.2%})")
        plt.axis('off')
        plt.tight_layout()
        plt.savefig(grad_cam_file, dpi=150, bbox_inches='tight')
        plt.close()
        results['files']['grad_cam'] = grad_cam_file
    
    # Sauvegarder LIME
    if 'lime' in results['xai'] and results['xai']['lime']:
        lime_file = os.path.join(output_dir, f"{base_name}_lime.png")
        plt.figure(figsize=(12, 4))
        plt.imshow(results['xai']['lime']['highlighted_image'])
        plt.title(f"LIME - R√©gions Importantes")
        plt.axis('off')
        plt.tight_layout()
        plt.savefig(lime_file, dpi=150, bbox_inches='tight')
        plt.close()
        results['files']['lime'] = lime_file
    
    # Sauvegarder rapport texte
    report_file = os.path.join(output_dir, f"{base_name}_report.txt")
    with open(report_file, 'w', encoding='utf-8') as f:
        f.write(results['report'])
    results['files']['report'] = report_file
    
    return results


def print_results(results):
    """Afficher les r√©sultats dans la console"""
    print("\n" + "="*70)
    print("üìä R√âSULTATS DE L'ANALYSE")
    print("="*70)
    
    pred = results['prediction']
    print(f"\nüéµ Fichier audio: {results['audio_file']}")
    print(f"   Dur√©e: {results['audio_info']['duration']:.2f}s")
    print(f"   Taux d'√©chantillonnage: {results['audio_info']['sample_rate']} Hz")
    
    print(f"\nü§ñ Mod√®le utilis√©: {pred['model_type']}")
    print(f"\n‚úÖ PR√âDICTION:")
    print(f"   Label: {pred['predicted_label']}")
    print(f"   Confiance: {pred['confidence']:.2%}")
    print(f"   Prob R√âEL: {pred['real_probability']:.4f}")
    print(f"   Prob FAUX: {pred['fake_probability']:.4f}")
    
    print(f"\nüîç EXPLAINABILIT√â XAI:")
    for method in results['xai']:
        if results['xai'][method]:
            print(f"   ‚úì {method.upper()}: G√©n√©r√©")
        else:
            print(f"   ‚úó {method.upper()}: √âchou√©")
    
    print(f"\nüíæ Fichiers g√©n√©r√©s:")
    for file_type, file_path in results['files'].items():
        if file_path:
            print(f"   ‚úì {file_type}: {file_path}")
    
    print("\n" + "="*70)


def process_audio(audio_path, model_type='mobilenet', output_dir='./results'):
    """
    Pipeline compl√®te: validation ‚Üí pr√©diction ‚Üí XAI ‚Üí visualisation
    """
    
    print("\n" + "="*70)
    print("üéµ DEEPFAKE AUDIO DETECTION PIPELINE")
    print("="*70)
    
    results = {
        'audio_file': audio_path,
        'audio_info': None,
        'prediction': None,
        'xai': {'grad_cam': None, 'lime': None, 'shap': None},
        'files': {'prediction': None, 'grad_cam': None, 'lime': None, 'report': None},
        'report': ''
    }
    
    # √âTAPE 1: VALIDATION
    print("\n[1/5] ‚úì Validation du fichier audio...")
    is_valid, error = AudioValidator.validate_file(audio_path)
    if not is_valid:
        print(f"      ‚úó Erreur: {error}")
        return results
    print(f"      ‚úì Fichier valide!")
    
    # R√©cup√©rer les infos audio
    try:
        results['audio_info'] = get_audio_info(audio_path)
        print(f"      ‚úì Dur√©e: {results['audio_info']['duration']:.2f}s")
        print(f"      ‚úì Sample rate: {results['audio_info']['sample_rate']} Hz")
    except Exception as e:
        print(f"      ‚úó Erreur lecture info: {e}")
        return results
    
    # √âTAPE 2: CONVERSION SPECTROGRAM
    print("\n[2/5] ‚úì Conversion audio ‚Üí spectrogram...")
    try:
        print(f"      ‚úì Spectrogram g√©n√©r√© (224√ó224 pixels)")
    except Exception as e:
        print(f"      ‚úó Erreur conversion: {e}")
        return results
    
    # √âTAPE 3: PR√âDICTION
    print("\n[3/5] ‚úì Pr√©diction avec mod√®le CNN...")
    try:
        detector = DeepfakeAudioDetector(model_type=model_type)
        results['prediction'] = detector.predict(audio_path)
        print(f"      ‚úì Mod√®le: {model_type}")
        print(f"      ‚úì Label: {results['prediction']['predicted_label']}")
        print(f"      ‚úì Confiance: {results['prediction']['confidence']:.2%}")
    except Exception as e:
        print(f"      ‚úó Erreur pr√©diction: {e}")
        return results
    
    # √âTAPE 4: EXPLAINABILIT√â XAI
    print("\n[4/5] ‚úì G√©n√©ration des explications XAI...")
    try:
        explainer = XAIExplainer(detector.model, model_type=model_type)
        
        # Grad-CAM
        print(f"      Grad-CAM...", end='', flush=True)
        try:
            results['xai']['grad_cam'] = explainer.grad_cam(audio_path)
            print(" ‚úì")
        except Exception as e:
            print(f" ‚úó ({str(e)[:50]})")
        
        # LIME
        print(f"      LIME...", end='', flush=True)
        try:
            results['xai']['lime'] = explainer.lime_explanation(audio_path, num_samples=500)
            print(" ‚úì")
        except Exception as e:
            print(f" ‚úó ({str(e)[:50]})")
        
        # SHAP (optionnel - peut √™tre lent)
        print(f"      SHAP...", end='', flush=True)
        try:
            results['xai']['shap'] = explainer.shap_explanation(audio_path, background_samples=50)
            print(" ‚úì")
        except Exception as e:
            print(f" ‚úó ({str(e)[:50]})")
    
    except Exception as e:
        print(f"      ‚úó Erreur XAI: {e}")
    
    # √âTAPE 5: SAUVEGARDE ET VISUALISATION
    print("\n[5/5] ‚úì Sauvegarde des r√©sultats...")
    try:
        output_dir = create_output_dir(output_dir)
        results = save_results(results, output_dir, audio_path)
        
        # G√©n√©rer rapport
        results['report'] = PredictionReport.generate_report(results['prediction'])
        
        print(f"      ‚úì R√©sultats sauvegard√©s dans: {output_dir}")
    except Exception as e:
        print(f"      ‚úó Erreur sauvegarde: {e}")
    
    # Afficher les r√©sultats
    print_results(results)
    
    return results


def main():
    """Point d'entr√©e principal"""
    parser = argparse.ArgumentParser(
        description='Pipeline de d√©tection deepfake audio avec XAI',
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
Exemples:
  python main.py audio.wav
  python main.py audio.wav --model vgg16
  python main.py audio.wav --model resnet50 --output ./mon_dossier
        """
    )
    
    parser.add_argument('audio', 
                       help='Chemin vers le fichier audio (.wav, .mp3, .ogg, .flac)')
    parser.add_argument('--model', 
                       choices=['mobilenet', 'vgg16', 'resnet50'],
                       default='mobilenet',
                       help='Mod√®le √† utiliser (default: mobilenet)')
    parser.add_argument('--output', 
                       default='./results',
                       help='Dossier de sortie (default: ./results)')
    
    args = parser.parse_args()
    
    # V√©rifier le fichier
    if not os.path.exists(args.audio):
        print(f"\n‚ùå Erreur: Fichier non trouv√©: {args.audio}")
        sys.exit(1)
    
    # Ex√©cuter la pipeline
    try:
        results = process_audio(args.audio, args.model, args.output)
        sys.exit(0)
    except KeyboardInterrupt:
        print("\n\n‚ö†Ô∏è  Interruption par l'utilisateur")
        sys.exit(1)
    except Exception as e:
        print(f"\n‚ùå Erreur fatale: {e}")
        import traceback
        traceback.print_exc()
        sys.exit(1)


if __name__ == "__main__":
    main()
